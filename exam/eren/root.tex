\documentclass{beamer}
\usetheme{Berlin}
\usecolortheme{beaver}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{listings}
\usepackage{courier}
\usepackage{amsmath}
\usepackage{lmodern}% http://ctan.org/pkg/lm
\usepackage{mathtools}
\usepackage[font={scriptsize,it}]{caption}
\usepackage{hyperref}
\usefonttheme{professionalfonts}

% code listings format
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}
\lstset{
  caption=\lstname
}

% inline code
\newcommand{\code}[1]{\texttt{#1}}

% command for centering boxes
\makeatletter
\newcommand*{\centerfloat}{%
  \parindent \z@
  \leftskip \z@ \@plus 1fil \@minus \textwidth
  \rightskip\leftskip
  \parfillskip \z@skip}
\makeatother

% command for adding figures
\newcommand{\fig}[3]{
  \begin{figure}[H]
  \centerfloat
    \includegraphics[width=\textwidth,height=#1,keepaspectratio]{figures/#2}
    \caption{#3}
  \end{figure}
}

% command for adding figures
\newcommand{\figNoCapt}[2]{
  \begin{figure}[H]
  \centerfloat
    \includegraphics[width=\textwidth,height=#1,keepaspectratio]{figures/#2}
  \end{figure}
}

% document info
\title{Exam presentation}
\subtitle{Assignment 2.2 and 2.3}
\author[Eren]{Eren~Can~Gungor\inst{1}}
\institute[DTU]
{
	\inst{1}
	Technical University of Denmark\\
	Digital Communication
}
\date{\today}
\subject{Digital Communication}


% front page
\begin{document}
\frame{\titlepage}

% slide 1
\begin{frame}
	\frametitle{Eye diagram}
	\begin{itemize}
		\item Plot composed by overlaying segments of different bit sequences
		\item Can be generated with an oscilloscope
		\item Shows effects of \emph{inter-symbol interference}
		\item Provides a qualitative measure of the system performance
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Eye diagram characteristics}
	\fig{9cm}{eye1.png}{Eye diagram of baseband antipodal signal}
	\begin{description}
		\item[$A$] Difference between high and low levels
		\item[$A_j$] Difference between $A$ and the eye opening
		\item[$T_j$] Deviations from ideal timing
		\item[$T_b$] Bit time period
	\end{description}
\end{frame}

\begin{frame}
	\frametitle{Eye diagram at different bandwidths}
	\begin{columns}
		\column{0.55\linewidth}
			\fig{8cm}{eye2.png}{Eye diagram for normalized bandwidths 0.3, 0.7, 1.2}
		\column{0.45\linewidth}
			\begin{itemize}
				\item Low BW: high amplitude and timing jitter
				\item High BW: no ISI, chances of higher noise
			\end{itemize}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Eye Diagram Graph}
	\fig{8cm}{important_eye_diag.png}{Important Eye Diagram}
\end{frame}
\begin{frame}
	\frametitle{ Q function 2.2}
In this part of the assignment we will investigate the  Normal (Gaussian) probability density function, $Q(u)$ function and it's relationship with complementary error function. It will also show how these theories will be related to the current communication systems by given assignment questions. Things we will look at are:

	\begin{itemize}
		\item Normal(Gaussian) Probability Density Function
		\item $Q(u)$ function
		\item $Q(u)$ function and it's relationship with complementary error function.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Probability Density Function}

Normal distribution/Gaussian distribution is a really important and in fact most commonly used distribution in statistics.  It is important because:
	\begin{itemize}
		\item Almost all variables are distributed approximately normally. They are approximately close
		\item Second reason is that statistical tests are derived from normal distribution and also work well if the distribution is approximately normal.
		\item Another reason is that it is only just characterised by two variables;
			\begin{itemize}
				\item It's mean $\mu$ and and standard deviation $\sigma$
			\end{itemize}
	\end{itemize}
For the communication systems;
Noise is an error or undesired random disturbance of a useful information in communication channel.The noise is a summation of unwanted or disturbing energy from natural and sometimes man-made sources.
\end{frame}
\begin{frame}
	\frametitle{Gaussian Noise}
If we look at simple basic model for the net effect at the receiver of noise in the communication system is to assumed additive, Gaussian noise. In this model we have two signal components one is deterministic signal and  the second component is the noise term, and is a quantity drawn from a Gaussian probability distribution with mean $0$ and some variance and it is  independent of the transmitted signal.
\end{frame}

\begin{frame}
	\frametitle{Q2.1 Plotting gaussian pdf and explain important variables}
Now we can put our theory in a practice in this given question, we have created the MATLAB file named\code{graphingpdf.m} which can be accessible from the report file. In this assignment important variables are

\begin{description}
	\item [mu] . This is the mean value ($\mu$) for the normal probability density function.
	\item [sigma] This the sensible standard deviation number. ($\sigma$).
	\item [MAX] 50; Maximum x value that x vector will get
	\item [MIN] -50; Minimum x value that x vector will get
\end{description}
\end{frame}

\begin{frame}
	\frametitle{Graph for Gaussian PDF}
\fig{5cm}{normalgaussiangraph.png}{Normal Gaussian pdf graph with defined intervals}
\end{frame}

\begin{frame}
	\frametitle{Explanation of $Q(u)$ function}
	$Q(u)$ function is a important variable for the Gaussian probability density function and cumulative distribution function. If we talk about $Q(u)$  function, there are two important points before we are going to derive the $Q(u)$ function.

	The $Q(u)$ function represents the area under the tail of a standard normal random variable and widely tabulated. Some interesting properties of the $Q- function$ are
	\begin{itemize}
		\item $Q(0)=1/2$
		\item $Q(-\infty)=1$
	\end{itemize}
\end{frame}
\begin{frame}
	\frametitle{Linking $Q(u)$ function to Gaussian probability density function and cumulative distribution function}
Now we can link $Q(u)$ function to Gaussian probability density function and cumulative distribution function
\begin{itemize}
	\item The Gaussian probability density function of unit variance and zero mean is $Z(x)=\frac{1}{\sqrt{2\pi}} \exp(\frac{-x^2}{4t})$
	\item And corresponding cumulative distribution function is $P(x)=\int_{-\infty}^{x} Z(t) dt$
	\item The Gaussian $Q$ function is defined as:
		\begin{itemize}
			\item $ Q(x) = 1-P(x)=\int_{x}^{-\infty} Z(t) dt$
		\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Assignment related question for the $Q(u)$ function}
To prove our theory behind, we have constructed the $Q(u)$ function plot that will able to take defined argument
values of relevance to the detection problems for digital communication receivers. MATLAB filed called \code{qfunction.m} has been created for this assigment. For the next step
Two important argument has been chosen for this assignment, those are:
	\begin{itemize}
		\item $R_12= 0 (Orthogonal Signals)$
		\item $R_12= -1( Antipodal Signals) $
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Graph for $Q(u)$ function assignment}
\fig{5cm}{question2_32_4.png}{Plotting $Q(u)$ function relevant to detection problems in digital communication receivers}
\end{frame}

\begin{frame}
	\frametitle{Relationship between inverse $Q(u)$ function and Complementary Error Function }
We know that $Q(u)$ function is :
\begin{itemize}
	\item $Q(z) = \int_{z}^{\infty} \frac{1}{\sqrt{2 \pi}} \exp(\frac{-y^2} {2}) dy$
\end{itemize}

And we have also learnt that complementary error function(erfc) is:
\begin{itemize}
	\item $erfc(z)= \frac{2}{\sqrt{\pi}} \int_{z}^{\infty} \exp(-x^2) dx$
\end{itemize}

From the limits of the integrals in previously defined $Q(z)$ function and $erfc(z)$ function that we can conclude that $Q$ function is directly related to erfc. Mathmetically by combining $Q$ function and $erfc$  we get the following Q function that directly related to erfc:

\begin{itemize}
	\item $Q(z)= \frac{1}{2} erfc(\frac{z}{\sqrt(2)})$
\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{MATLAB code for user-defined $Q$ function}
We also note that MATLAB does not have built in function.So we have created a MATLAB file that uses erfc function to do the calculations and simulation process related to the $Q(u)$ function. It is accessible from the Source code section under the name of \code{qfn.m}.
\end{frame}

\begin{frame}
	\frametitle { Assignment 2.3}
In assignment three, we will look into optimising our filter by using the $Q$ function and error functions that we have learnt from the part 2 of this Assignment. The important things we will specifically look in these chapter are:
\begin{itemize}
	\item Additive White Gaussian Noise for Matched Filter
	\item Matched Filter
	\item Correlator Filter
	\item Noise and Shape related problems in Matched Filter
\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Additive White Gaussian Noise for Matched Filter}
For a working principle, The signal is multiplied by a locally stored reference copy ,and integrated over time.
To understand the principles of a matched filter receiver for binary data in white Gaussian noise, thus using the so called AWGN (Additive White Gaussian Noise) model. We have firstly introduced the figure below.
\fig{5cm}{figure_31.png}{AWGN for Matched Filter}
\end{frame}

\begin{frame}
	\frametitle{Principles of AWGN for Matched Filter}
The matched filter correlates the incoming signal with a locally stored reference copy of the transmit waveform. The matched filter maximizes the signal-to-noise ratio for a known signal. It can be shown to be the optimal detector if
\begin{itemize}
	\item The channel produces Additive White Gaussian Noise (AWGN)
	\item The channel is linear and time-invariant (LTI)
	\item An exact time reference is available, the signal amplitude as a function of time is precisely known.
\end{itemize}
In our report, we have explicitly explained math behind how to apply these principles to achieve maxisimed signal to noise ratio.
\end{frame}

\begin{frame}
	\frametitle{Another example on how system works for AWGN Matched Filter}
	\fig{5cm}{working_principle_mf.png} {Working Principle of AWGN Matched Filter}
\end{frame}
\begin{frame}
	\frametitle{Assignment Questions that related to the Matched Filter}
There are several questions that has been done in regards to the Matched Filter. The first question was understanding how \code{c8ce1} works.

Firstly, code was not working properly so we have changed it and there were not enough explanation for the process and what it does.

Basically code was calculating delay estimate, power in both reference vector and measurement vector, finding max for the cross-correlation matrix by using sine waves. 
\end{frame}

\begin{frame}
	\frametitle{Creating a User Defined $Q$ function}
To run our code for assignments 3.4 and 3.5 we have created a user defined  qfn function. The code has been created as a \code{qfn.m} which can be accessible from the report.
\end{frame}

\begin{frame}
	\frametitle{Question 3.4 and 3.5}
For the questions 3.4  and 3.5 we have modified and changed the \code{ce9e1.m} MATLAB script. Code was broken and it was only taken 4 inputs. We have modified in a way that it can take up 8 inputs also we have graphed with given 8 correlation coefficients. Those were;
$[-1, -0.75, -0.5, 0, 0.5, 0.75, 0.8 ,0.995]$ . To prove that we did correct calculation and simulation graph in the next slight can be seen.
\end{frame}

\begin{frame}
	\frametitle{Graph with 8 Correlation Coefficient Inputs}
	\fig{5cm}{question351.png}{$P_E $ over $N_o$ graph for 8 correlation coefficient Inputs}
\end{frame}

\begin{frame}
	\frametitle{Construction of Matched filter by a Correlator}
To understand this concept, we have provided a Correlator Match Filter below. The cross-correlator does the cross-correlation between the noisy signal and noiseless signal.

The difference between Correlator and matched filter, matched filter does the convolution between the received signal and the time-reversed copy of the the reference signal but important point is both of them will give us same output.
	\fig{3cm}{correlator_matched_filter.png}{Correlator matched Filter}
\end{frame}
\begin{frame}
	\frametitle{Cross-Correlation Functions }

\begin{itemize}
	\item $\int_{0}^{T} r(t) f_k(t)=\int_{0}^{T} [s_m(t)+n(t)] f_k(t) dt$
	\item $r_k(t)=s_m(t)+n_k(t)$
	\item $\int_{0}^{T} s_m(t) f_k(t) $ for the values of $k= 1,2,3,4,5,...$
	\item $\int_{0}^{T} n(t) f_k(t) $ for the values of $k=1,2,3,4,5.....$
\end{itemize}

Now our signal has been represented by the $s_m(t)$ and the $n(k)$ (random variables as noise)

Now the signal can be represent $r(t)$ as

\begin{itemize}
	\item $r(t)= \sum\limits_{k=1}^N = s_m(t) f_k(t)+ n(t)'+\sum\limits_{k=1}^N = n_k(t) f_k(t)$
	\item $\sum\limits_{k=1}^N = r_k(t) f_k(t)$
\end{itemize}

As we can see that $n(t)'$ is irrelevant to which signal is going to transmitted. The decision will be made upon entirely on correlator output and the basis functions.
\end{frame}

\begin{frame}
	\frametitle{Deriving Matched Filter Functions}
Now we can compare with Matched filter output. For matched filter, we use $N$ bank linear filters. Impulse responses of the $N$ filters are;
\begin{itemize}
	\item $h_k(t)=f_k(T-t)$ for invertals between , $0<t<T$
\end{itemize}

The output filters become:
\begin{itemize}
	\item $y_k(t)=\int_{0}^{T} r(\tau) f_k(T-\tau)d(\tau)$
	\item $\int_{0}^{T} r(\tau) f_k(T-t+\tau)d(\tau)$ for the $k= 1,2,3,4,5,...N$
\end{itemize}
If we sample outputs of the linears at $t=T$
\begin{itemize}
\item $y_k(T)=\int_{0}^{T} r(\tau) f_k(\tau)d(\tau)$ which will eventually become $r_k$
\end{itemize}

Hence our theoritical approach has been proved by mathematical derivation of matched filter and cross-correlator. Both have same output even though calculations have been done in a different way for both.
\end{frame}

\begin{frame}
	\frametitle{Noise on the timing Synchronization in The Receiver}
It is possible that the exact arrival time of received signal can be in error. That causes the sampling at wrong instances of matched filter output. That means receiver is no longer an optimal receiver because system samples output different point rather than it's maximum. That will cause a decrease of the amplitude of sampled signal and therefore, signal to noise ratio will also decrease. As a result probability of error become larger in timing synchronization errors. 
\end{frame}

\begin{frame}
	\frametitle{Bit Error Probability in Matched Filter}
To find out bit error probability in a system with matched filter, we first need to define threshold. $s_1(T)$ and $s_2(T)$ are the inputs to the matched filter, $s_{01}(T)$ and $s_{02}(T)$ are the outputs of the matched filter. Then the equation becomes
\begin{itemize}
	\item $s_{01}(T)=\int_{-\infty}^{infty} h(\lambda) s_1(T-\lambda) d \lambda $
    	\item $ \int_{-\infty}^{infty} ( s_2(T-\lambda) - s_1(T-\lambda)) s_1(T-\lambda) d \lambda $
	\item  $\int_{-\infty}^{infty} s_2(u) s_1(u) du - \int_{-\infty}^{\infty} (s_1(u))^2 du $
    	\item $ \sqrt{E_1 E_2} \rho_{12} - E_1 $
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{ Continuing the derivation}
and by the equations symmetric to the ones above we get
$ s_{02}(T)=E_2 - \sqrt{E_1 E_2} \rho_{12}$\\
Then optimum threshold is the average of $s_{01}$ and $s_{02}$,\\
$ k_{opt}=\frac{1}{2}(E_2 - E_1)$\\
We have probability of error equation
$P_e = P(Error|s_1(t)) P(s_1(t)) + P(Error|s_2(t)) P(s_2(t))$.\\
For the equiprobable symbol selection case we have \\
$P_e = P(Error|s_1(t)) \frac{1}{2} + P(Error|s_2(t)) \frac{1}{2}$\\
This can be formed as
$P_e=Q(\frac{s_{02}(T)-s_{01}(T)}{2 \sigma_0})$ \\
if we make the selection of threshold as $k_opt$.
We put values of $s_{01}$ and $s_{02}$ to the equation and it becomes
$P_e=Q(\frac{E_1+E_2-2\rho \sqrt{E_1 E_2}}{2 \sigma_0}\bigg)$

\end{frame}


\begin{frame}
	\frametitle{Link budget model}
	\begin{itemize}
		\item A way of estimating the power of a received signal
		\item Takes into account all the gains and losses of transmitter, channel, and receiver
		\begin{equation}
			P_R = \left(\frac{\lambda}{4 \pi d}\right)^2 \frac{P_T G_T G_R}{L_0};
		\end{equation}
		\item In decibels:
		\begin{equation}
			P_{R, dB} = 20\log_{10}\left(\frac{4 \pi d}{\lambda}\right) + {ERP}_{dB} + G_{R, dB} - L_{0, dB};
		\end{equation}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Link budget model variables}
	\begin{description}
		\item[$(\frac{4 \pi d}{\lambda})^2$] Free-space loss
		\item[$ERP = P_T G_T$] Effective radiated power
		\item[$G_R$] Gain of receiver antenna
		\item[$L_0$] Other losses, link budget margin
	\end{description}
\end{frame}

\begin{frame}
	\frametitle{$SNR$ calculation}
	\begin{itemize}
		\item Signal-to-noise ratio in decibels:
	\end{itemize}
	\begin{equation}
		{SNR}_{dB} = P_{R, dB} - P_{int, dB}
	\end{equation}
	\begin{description}
		\item[$P_R$] Calculated using link budget model
		\item[$P_{int}$] Noise power, proportional to the receiver noise temperature and the transmission bandwidth
	\end{description}
\end{frame}

\begin{frame}
	\frametitle{$P_E$ calculation}
	\begin{itemize}
		\item Bit error probability for BSFK transmissions:
	\end{itemize}
	\begin{equation}
		P_E = Q\left(\sqrt{\frac{2E_b}{N_0}}\right)
	\end{equation}
	\begin{enumerate}
		\item ratio $E_b / N_0$ derived from $SNR = \rightarrow \frac{E_b}{N_0 B T_b}$
		\item For binary BPSK, $B = 2/T_b$
		\item Factor $B T_b$ is 2, or 3 dB
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Impact of $d$, $\lambda$, $B$}
	\begin{columns}
		\column{0.5\linewidth}
			\figNoCapt{2.75cm}{d_lambda.png}
			\figNoCapt{2.75cm}{lambda_b.png}
		\column{0.5\linewidth}
			\figNoCapt{2.75cm}{d_b.png}
			\begin{itemize}
				\item $SNR$ and $P_E$ are negatively affected by:
				\begin{itemize}
					\item Higher distance $d$
					\item Lower wavelength $\lambda$
					\item Wider bandwidth $B$ (lower influence)
				\end{itemize}
			\end{itemize}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Impact of $P_T$}
	\begin{itemize}
		\item $P_E$ for $P_T$ at 50 W, 5 W, and 500 mW:
	\end{itemize}
	\begin{equation}
		\code{1.4062e-05   9.2684e-02   3.3768e-01}
	\end{equation}
	\fig{4cm}{pe_over_pt.png}{$P_E$ over values of $P_T$}
\end{frame}

\begin{frame}
	\frametitle{Alternative modulation: ASK}
	\begin{itemize}
		\item Amplitude-shift keying
		\fig{2.5cm}{ask.png}{Bit stream modulated using ASK}
		\item 0-bit represented as 0
		\item 1-bit represented as $A\cos(2 \pi f_c t)$
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Alternative modulation: ASK ($P_E$ calculation)}
	\begin{itemize}
		\item Correlation coefficients:
		\begin{itemize}
			\item $\rho_{12} = \frac{1}{\sqrt{E_1 E_2}} \int_{-\infty}^{\infty} s_1(t) s_2(t) dt = 0$
			\item $R_{12} = \frac{\sqrt{E_1 E_2}}{E_b}\rho_{12} = 0$
		\end{itemize}
		\item $SNR$ to $E_b/N_0$: conversion factor $B T_b = 2$
		\item Bit error probability:
	\end{itemize}
	\begin{equation}
		P_E = Q\left(\sqrt{\left(1 - R_{12}\right) \frac{E_b}{N_0}}\right) = Q\left(\sqrt{\frac{E_b}{N_0}}\right)
	\end{equation}
\end{frame}

\begin{frame}
	\frametitle{Alternative modulation: FSK}
	\begin{itemize}
		\item Frequency-shift keying
		\fig{2.5cm}{fsk.png}{Bit stream modulated using FSK}
		\item 0-bit represented as $A\cos(\omega_c t)$
		\item 1-bit represented as $A\cos((\omega_c + \Delta \omega) t)$
		\item Assumptions: $\omega_c = \frac{2 \pi n}{T}$ and $\Delta\omega = \frac{2 \pi m}{T}$
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Alternative modulation: FSK ($P_E$ calculation)}
	\begin{itemize}
		\item Correlation coefficient $R_{12} = \frac{\sqrt{E_1 E_2}}{E_b}\rho_{12} = 0$
		\item $SNR$ to $E_b/N_0$: conversion factor $B T_b = 2.5$
		\item Bit error probability:
	\end{itemize}
	\begin{equation}
		P_E = Q\left(\sqrt{\left(1 - R_{12}\right) \frac{E_b}{N_0}}\right) = Q\left(\sqrt{\frac{E_b}{N_0}}\right)
	\end{equation}
\end{frame}


\end{document}
