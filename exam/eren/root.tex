\documentclass{beamer}
\usetheme{Berlin}
\usecolortheme{beaver}
\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage{listings}
\usepackage{courier}
\usepackage{amsmath}
\usepackage{lmodern}% http://ctan.org/pkg/lm
\usepackage{mathtools}
\usepackage[font={scriptsize,it}]{caption}
\usepackage{hyperref}
\usefonttheme{professionalfonts}

% code listings format
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}
\lstset{
  caption=\lstname
}

% inline code
\newcommand{\code}[1]{\texttt{#1}}

% command for centering boxes
\makeatletter
\newcommand*{\centerfloat}{%
  \parindent \z@
  \leftskip \z@ \@plus 1fil \@minus \textwidth
  \rightskip\leftskip
  \parfillskip \z@skip}
\makeatother

% command for adding figures
\newcommand{\fig}[3]{
  \begin{figure}[H]
  \centerfloat
    \includegraphics[width=\textwidth,height=#1,keepaspectratio]{figures/#2}
    \caption{#3}
  \end{figure}
}

% command for adding figures
\newcommand{\figNoCapt}[2]{
  \begin{figure}[H]
  \centerfloat
    \includegraphics[width=\textwidth,height=#1,keepaspectratio]{figures/#2}
  \end{figure}
}

% document info
\title{Exam presentation}
\subtitle{Assignment 2 and Assignment 3}
\author[Eren]{Eren~Can~Gungor\inst{1}}
\institute[DTU]
{
	\inst{1}
	Technical University of Denmark\\
	Digital Communication
}
\date{\today}
\subject{Digital Communication}


% front page
\begin{document}
\frame{\titlepage}

% slide 1
\begin{frame}
	\frametitle {The Eye Diagram for a Digital Communication Channel}
\begin{itemize}
	\item An eye diagram is used to see every possible symbol transition in one graph.
	\item One can analyze these transitions to see inter-symbol interference (ISI) effects.
	\item Generating an eye diagram requires plotting of overlapping signals of $k$-symbol duration where $k$ is an integer more than one since we need to see the transitions between symbols.
	\item With real signals, it can be generated with an oscilloscope with time sweep frequency $1/kT_s$ where $T_s$ is the symbol duration.
	\item With using an eye diagram, one can make comments on probability of error by looking at the eye opening.

\end{itemize}
\end{frame}

\begin{frame}
\begin{itemize}
	\item Channel model is assumed as a low pass filter.
	\item Butterworth filters with different cut-off frequencies are used as low pass filters to demonstrate the effects of ISI with an eye diagram. 
	\item Normalized bandwidths are used as parameters of filters in the code. If normalized bandwidth is $B$ and symbol rate is $n_{sym}$ symbol per second then the bandwidth of the filter is given as $Bn_{sym}$ Hz.

	\item We have sampling frequency $f_s=n_{sym} n_{samp}$ samples per second where $n_{samp}$ is the sample number in a symbol. To obtain a filter with bandwidth $Bn_{sym}$, we should use normalized frequency $f_{normalized}=\frac{Bn_{sym}}{f_S/2}=2B/n_{samp}$ ($\pi$ rad/sec).
\end{itemize}
\end{frame}


\begin{frame}
	\frametitle{Eye diagram characteristics}
	\fig{3cm}{eye_diag_imp.png}{Eye diagram of baseband antipodal signal}
	\begin{description}
		\item[$A$] Difference between high and low levels
		\item[$A_j$] Difference between $A$ and the eye opening
		\item[$T_j$] Deviations from ideal timing
		\item[$T_b$] Bit time period
	\end{description}
\end{frame}

\begin{frame}
	\frametitle{Eye diagram at different bandwidths}
	\begin{columns}
		\column{0.55\linewidth}
			\fig{8cm}{eye2.png}{Eye diagram for normalized bandwidths 0.3, 0.7, 1.2}
		\column{0.45\linewidth}
			\begin{itemize}
				\item ISI leads to $T_j$. increasing the signal bandwidth will result in increased slope that  which will result in more open eye
				\item High BW: high amplitude and timing jitter.
				\item Low BW: no ISI, chances of higher noise
			\end{itemize}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Eye Diagram Graph}
	\fig{8cm}{important_eye_diag.png}{Important Eye Diagram}
\end{frame}
\begin{frame}
	\frametitle{ Q function 2.2}
In this part of the assignment we will investigate the  Normal (Gaussian) probability density function, $Q(u)$ function and it's relationship with complementary error function. It will also show how these theories will be related to the current communication systems by given assignment questions. Things we will look at are:

	\begin{itemize}
		\item Normal(Gaussian) Probability Density Function
		\item $Q(u)$ function
		\item $Q(u)$ function and it's relationship with complementary error function.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Probability Density Function}

Normal distribution/Gaussian distribution is a really important and in fact most commonly used distribution in statistics.  It is important because:
	\begin{itemize}
		\item Almost all variables are distributed approximately normally. They are approximately close
		\item Second reason is that statistical tests are derived from normal distribution and also work well if the distribution is approximately normal.
		\item Another reason is that it is only just characterised by two variables;
			\begin{itemize}
				\item It's mean $\mu$ and and standard deviation $\sigma$
			\end{itemize}
	\end{itemize}
For the communication systems;
Noise is an error or undesired random disturbance of a useful information in communication channel.The noise is a summation of unwanted or disturbing energy from natural and sometimes man-made sources.
\end{frame}

\begin{frame}
	\frametitle{Q2.1 Plotting gaussian pdf and explain important variables}
Now we can put our theory in a practice in this given question, we have created the MATLAB file named\code{graphingpdf.m} which can be accessible from the report file. In this assignment important variables are

\begin{description}
	\item [mu] . This is the mean value ($\mu$) for the normal probability density function.
	\item [sigma] This the sensible standard deviation number. ($\sigma$).
	\item [MAX] 50; Maximum x value that x vector will get
	\item [MIN] -50; Minimum x value that x vector will get
\end{description}
\end{frame}

\begin{frame}
	\frametitle{Graph for Gaussian PDF}
\fig{5cm}{normalgaussiangraph.png}{Normal Gaussian pdf graph with defined intervals}
\end{frame}

\begin{frame}
	\frametitle{Explanation of $Q(u)$ function}
Cumulative distribution function (CDF) shows the probability that random variable $X$ is less than a value $x$,i.e., CDF $F(x)=Pr(X\leq x)=\int\limits^x_{-\infty}f(x)dx$ where $f(x)$ is normal probability density function. The probability that random variable $X$ is larger than a value $x$ defined as $Q$ function. Therefore, $Q(u)=1-F(u)$. Normal distribution has a $\mu$ value 0 and $\sigma$ value 1. By taking account these parameters, if we insert Gaussian PDF $f(x)$ into account $Q$ function becomes $Q(u)=\int\limits^{\infty}_u \frac{1}{ \sqrt{2\pi}} \exp({\frac{-y^2}{2}})dy$. For the general Gaussian PDF with $\mu$ and $\sigma$, a normalization should be done like $Q(\frac{u-\mu}{\sigma})$ as shown in book at page 295. In Fig. 3, shaded area shows the value of $Q$ function.
\end{frame}

\begin{frame}
\fig{5cm}{fig3.png}{$Q(u)$ graph }
\end{frame}



\begin{frame}
	\frametitle{Assignment related question for the $Q(u)$ function}
To prove our theory behind, we have constructed the $Q(u)$ function plot that will able to take defined argument
values of relevance to the detection problems for digital communication receivers. MATLAB filed called \code{qfunction.m} has been created for this assigment. For the next step
Two important argument has been chosen for this assignment, those are:
	\begin{itemize}
		\item $R_{12}= 0 (Orthogonal Signals)$
		\item $R_{12}= -1( Antipodal Signals) $
	\end{itemize}
\end{frame}

\begin{frame}
\fig{5cm}{figure_for_23.png}{$Q(u)$ graph }
\end{frame}

\begin{frame}
	\frametitle{Q inverse function and contemporary error function};
\begin{itemize}
	\item $Q(u)=\int\limits^{\infty}_u \frac{1}{ \sqrt{2\pi}} \exp({\frac{-y^2}{2}})dy$.
	\item $erf(u)=\frac{2}{\sqrt{\pi}} \int\limits_0^u e^{-y^2} dy$
	\item $erfc(u)=1-erf(u)=\frac{2}{\sqrt{\pi}} \int\limits_u^\infty e^{-y^2} dy$
	\item $Q(u)=\frac{1}{2} erfc\bigg( \frac{x}{\sqrt[]{2}} \bigg)$
	\item $erfc(v)=2Q \big( \sqrt[]{2} v \big)$
\end{itemize}
We also have inverse Q function that maps for any y value that gives $Q(x)=y$ to x ($Q^{-1}(y)=x$).
These functions are defined in MATLAB and can be directly used with functions \it{qfunc(x)}, \it{qfuncinv(x)}, \it{erf(x)} and \it{erfc(x)} commands.
\end{frame}

\begin{frame}
	\fig{5cm}{fig7.png}{$Q(u)^(-1)$ graph}
\end{frame}

\begin{frame}
	\frametitle{MATLAB code for user-defined $Q$ function}
We also note that MATLAB does not have built in function.So we have created a MATLAB file that uses erfc function to do the calculations and simulation process related to the $Q(u)$ function. It is accessible from the Source code section under the name of \code{qfn.m}.
\end{frame}

\begin{frame}
	\frametitle { Assignment 2 Part 3}
In assignment two, part 3, we will look into optimising our filter by using the $Q$ function and error functions that we have learnt from the part 2 of this Assignment. The important things we will specifically look in these chapter are:
\begin{itemize}
	\item Additive White Gaussian Noise for Matched Filter
	\item Matched Filter
	\item Correlator Filter
	\item Noise and Shape related problems in Matched Filter
\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Additive White Gaussian Noise for Matched Filter}
Matched filter receiver is an optimum receiver structure in terms of minimum prob- ability of error in communication systems. Derivation of the optimality of the strucure is given in the book. Block diagram of matched filter output for binary data in AWGN data is given in Fig.5 which is taken from the book page 409

\end{frame}
	
\begin{frame}
	\frametitle{Working Principle}
For a working principle, The signal is multiplied by a locally stored reference copy ,and integrated over time.
To understand the principles of a matched filter receiver for binary data in white Gaussian noise, thus using the so called AWGN (Additive White Gaussian Noise) model. We have firstly introduced the figure below.
\fig{5cm}{figure_31.png}{AWGN for Matched Filter}
\end{frame}

\begin{frame}
	\frametitle{Principles of AWGN for Matched Filter}
Received signal $y(t)$ should be passed through matched filters $s_1(T-t)$ and $s_2(T-t)$ and their difference must be sampled at $t=T$ and then a decision should be according to the optimal threshold value. $s_1(t)$ and $s_2(t)$ are original signals corresponds to binary data and $s_1(t)<s_2(t)$ is assumed. Optimal threshold value is $\frac{E_2-E_1}{2}$ where $E_2$ and $E_1$ signal energies which are finite.
\end{frame}

\begin{frame}
	\frametitle{Another example on how system works for AWGN Matched Filter}
	\fig{5cm}{working_principle_mf.png} {Working Principle of AWGN Matched Filter}
\end{frame}

\begin{frame}
	\frametitle{Creating a User Defined $Q$ function}
To run our code for assignments 3.4 and 3.5 we have created a user defined \code{qfn.m} function. The code has been created as a \code{qfn.m} which can be accessible from the report.
\end{frame}

\begin{frame}
	\frametitle{Q $3.4$ and $3.5$ $P_e$ Graph For Various Correlation Coefficients}
We enter [-1 -0.75 -0.5 0 0.5 0.75 0.8 .995] matrix when we run script and it plots probability of error for different correlation values. For lower correlation values the probability of error decreases since the signals affect each other less. As the correlation values increase, the signals affect each other, e.g., if one is sent both matched filters high values of outputs and with noise the one that isn't sent may become higher easily. In Fig. 6, the results can be seen as expected.
\end{frame}

\begin{frame}
	\frametitle{Graph with 8 Correlation Coefficient Inputs}
	\fig{5cm}{question351.png}{$P_E $ over $N_o$ graph for 8 correlation coefficient Inputs}
\end{frame}
\begin{frame}
	\frametitle{Matched Filter and Correlator}

In matched filter, $h(t)=s(T-t)$ and output of this filter can be written as convolution
$$h(t)*y(t)=\int\limits^T_0s(T-\tau)y(t-\tau)d\tau$$
where $y(t)$ is received signal. Since system samples signals at t=T and with change of variables to $\alpha=T-\tau$
\end{frame} 

\begin{frame}
	\frametitle{ Derivation continues}
we can rewrite above equation as
$$v(T)=\int\limits^T_0s(\alpha)y(\alpha)d\alpha$$
where $v(T)$ is sampled version of convolution. The result is integration of the multiplication of received signal with original signal $s(t)$ and it is simply correlation of signals. Therefore, one can implement matched filter receiver with correlator as shown above. 

\end{frame}

\begin{frame}
	\frametitle{Noise on the timing Synchronization in The Receiver}
It is possible that the exact arrival time of received signal can be in error. That causes the sampling at wrong instances of matched filter output. That means receiver is no longer an optimal receiver because system samples output different point rather than it's maximum. That will cause a decrease of the amplitude of sampled signal and therefore, signal to noise ratio will also decrease. As a result probability of error becomes larger in timing synchronisation errors. 
\end{frame}

\begin{frame}
	\frametitle{Bit Error Probability in Matched Filter}
To find out bit error probability in a system with matched filter, we first need to define threshold. $s_1(T)$ and $s_2(T)$ are the inputs to the matched filter, $s_{01}(T)$ and $s_{02}(T)$ are the outputs of the matched filter. Then the equation becomes
\begin{itemize}
	\item $s_{01}(T)=\int_{-\infty}^{\infty} h(\lambda) s_1(T-\lambda) d \lambda $
    	\item $ \int_{-\infty}^{\infty} ( s_2(T-\lambda) - s_1(T-\lambda)) s_1(T-\lambda) d \lambda $
	\item  $\int_{-\infty}^{\infty} s_2(u) s_1(u) du - \int_{-\infty}^{\infty} (s_1(u))^2 du $
    	\item $ \sqrt{E_1 E_2} \rho_{12} - E_1 $
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{ Continuing the derivation}
and by the equations symmetric to the ones above we get
$ s_{02}(T)=E_2 - \sqrt{E_1 E_2} \rho_{12}$\\
Then optimum threshold is the average of $s_{01}$ and $s_{02}$,\\
$ k_{opt}=\frac{1}{2}(E_2 - E_1)$\\
We have probability of error equation
$P_e = P(Error|s_1(t)) P(s_1(t)) + P(Error|s_2(t)) P(s_2(t))$.\\
For the equiprobable symbol selection case we have \\
$P_e = P(Error|s_1(t)) \frac{1}{2} + P(Error|s_2(t)) \frac{1}{2}$\\
This can be formed as
$P_e=Q(\frac{s_{02}(T)-s_{01}(T)}{2 \sigma_0})$ \\
if we make the selection of threshold as $k_{opt}$.
We put values of $s_{01}$ and $s_{02}$ to the equation and it becomes
$P_e=Q(\frac{E_1+E_2-2\rho \sqrt{E_1 E_2}}{2 \sigma_0}\bigg)$

\end{frame}


\begin{frame}
	\frametitle{Link budget model}
	\begin{itemize}
		\item A way of estimating the power of a received signal
		\item Takes into account all the gains and losses of transmitter, channel, and receiver
		\begin{equation}
			P_R = \left(\frac{\lambda}{4 \pi d}\right)^2 \frac{P_T G_T G_R}{L_0};
		\end{equation}
		\item In decibels:
		\begin{equation}
			P_{R, dB} = 20\log_{10}\left(\frac{4 \pi d}{\lambda}\right) + {ERP}_{dB} + G_{R, dB} - L_{0, dB};
		\end{equation}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Link budget model variables}
	\begin{description}
		\item[$(\frac{4 \pi d}{\lambda})^2$] Free-space loss.Signal strength loss occurring in a line-of-sight path through free space (usually air), without accounting for reflection or diffraction.
			\begin{equation}
	{FSPL} = \left(\frac{4 \pi d}{\lambda}\right)^2
			\end{equation}
		\item[$ERP = P_T G_T$] Effective radiated power. Equivalent power transmitted equally in all directions, from a theoretical spherically radiating source.
			\begin{equation}
	{ERP}_{dB} = 10\log_{10}(P_T) + G_{T, dB}
			\end{equation}
		\item[$G_R$] Gain of receiver antenna.
		\item[$L_0$] Other losses, link budget margin
	\end{description}
\end{frame}

\begin{frame}
	\frametitle{$SNR$ calculation}
	\begin{itemize}
		\item Signal-to-noise ratio in decibels:
	\end{itemize}
	\begin{equation}
		{SNR}_{dB} = P_{R, dB} - P_{int, dB}
	\end{equation}
	\begin{description}
		\item[$P_R$] Calculated using link budget model
		\item[$P_{int}$] Noise power, proportional to the receiver noise temperature and the transmission bandwidth
			\begin{equation}
	P_{int} = k T_R B
\end{equation}

where $T_R$ is the noise temperature of the receiver, $B$ is the bandwidth of the transmission, and $k$ is the Boltzmann constant.
	\end{description}
\end{frame}

\begin{frame}
	\frametitle{$P_E$ calculation}
	\begin{itemize}
		\item Bit error probability for BSFK transmissions:
	\end{itemize}
	\begin{equation}
		P_E = Q\left(\sqrt{\frac{2E_b}{N_0}}\right)
	\end{equation}
	\begin{enumerate}
		\item ratio $E_b / N_0$ derived from $SNR = \rightarrow \frac{E_b}{N_0 B T_b}$
		\item For binary BPSK, $B = 2/T_b$
		\item Factor $B T_b$ is 2, or 3 dB
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Impact of $d$, $\lambda$, $B$}
	\begin{columns}
		\column{0.5\linewidth}
			\figNoCapt{2.75cm}{d_lambda.png}
			\figNoCapt{2.75cm}{lambda_b.png}
		\column{0.5\linewidth}
			\figNoCapt{2.75cm}{d_b.png}
			\begin{itemize}
				\item $SNR$ and $P_E$ are negatively affected by:
				\begin{itemize}
					\item Higher distance $d$
					\item Lower wavelength $\lambda$
					\item Wider bandwidth $B$ (lower influence)
				\end{itemize}
			\end{itemize}
	\end{columns}
\end{frame}

\begin{frame}
	\frametitle{Impact of $P_T$}
	\begin{itemize}
		\item $P_E$ for $P_T$ at 50 W, 5 W, and 500 mW:
	\end{itemize}
	\begin{equation}
		\code{1.4062e-05   9.2684e-02   3.3768e-01}
	\end{equation}
	\fig{4cm}{pe_over_pt.png}{$P_E$ over values of $P_T$}
\end{frame}

\begin{frame}
	\frametitle{Alternative modulation: ASK}
	\begin{itemize}
		\item Amplitude-shift keying
		\fig{2.5cm}{ask.png}{Bit stream modulated using ASK}
		\item 0-bit represented as 0
		\item 1-bit represented as $A\cos(2 \pi f_c t)$
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Alternative modulation: ASK ($P_E$ calculation)}
	\begin{itemize}
		\item Correlation coefficients:
		\begin{itemize}
			\item $\rho_{12} = \frac{1}{\sqrt{E_1 E_2}} \int_{-\infty}^{\infty} s_1(t) s_2(t) dt = 0$
			\item $R_{12} = \frac{\sqrt{E_1 E_2}}{E_b}\rho_{12} = 0$
		\end{itemize}
		\item $SNR$ to $E_b/N_0$: conversion factor $B T_b = 2$
		\item Bit error probability:
	\end{itemize}
	\begin{equation}
		P_E = Q\left(\sqrt{\left(1 - R_{12}\right) \frac{E_b}{N_0}}\right) = Q\left(\sqrt{\frac{E_b}{N_0}}\right)
	\end{equation}
Whilst the formula is similar to the one previously introduced for the
calculation of $P_E$ in a BPSK transmission, it lacks a $\sqrt{2}$ term. Therefore, the signal-to-noise radio of a ASK transmission has to be $3 dB$ higher in order to maintain the same performances.
\end{frame}

\begin{frame}
	\frametitle{Alternative modulation: FSK}
	\begin{itemize}
		\item Frequency-shift keying
		\fig{2.5cm}{fsk.png}{Bit stream modulated using FSK}
		\item 0-bit represented as $A\cos(\omega_c t)$
		\item 1-bit represented as $A\cos((\omega_c + \Delta \omega) t)$
		\item Assumptions: $\omega_c = \frac{2 \pi n}{T}$ and $\Delta\omega = \frac{2 \pi m}{T}$
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Alternative modulation: FSK ($P_E$ calculation)}
	\begin{itemize}
		\item Correlation coefficient $R_{12} = \frac{\sqrt{E_1 E_2}}{E_b}\rho_{12} = 0$
		\item $SNR$ to $E_b/N_0$: conversion factor $B T_b = 2.5$
		\item Bit error probability:
	\end{itemize}
	\begin{equation}
		P_E = Q\left(\sqrt{\left(1 - R_{12}\right) \frac{E_b}{N_0}}\right) = Q\left(\sqrt{\frac{E_b}{N_0}}\right)
	\end{equation}
	
However, when deriving the $Eb/N0$ ratio from the signal-to-noise ratio, the required bandwidth is given by $2.5/T$, so the factor $BTb$ becomes $2.5$, or around $4 dB$.
\end{frame}


\end{document}
